; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -verify-machineinstrs -mtriple arm64e-apple-darwin | FileCheck %s --check-prefixes=CHECK,DYN-CM-DFL
; RUN: llc < %s -verify-machineinstrs -mtriple arm64e-apple-darwin -code-model=large                      | FileCheck %s --check-prefixes=CHECK,DYN,DYN-CM-LRG

target datalayout = "e-m:o-i64:64-i128:128-n32:64-S128"

; Check code references.

define i8* @test_global_zero_disc() {
; DYN-LABEL: test_global_zero_disc:
; DYN:       ; %bb.0:
; DYN-NEXT:    adrp x16, _g@GOTPAGE
; DYN-NEXT:    ldr x16, [x16, _g@GOTPAGEOFF]
; DYN-NEXT:    paciza x16
; DYN-NEXT:    mov x0, x16
; DYN-NEXT:    ret
;
  %tmp0 = bitcast { i8*, i32, i64, i64 }* @g.ptrauth.ia.0 to i8*
  ret i8* %tmp0
}

define i8* @test_global_offset_zero_disc() {
; DYN-LABEL: test_global_offset_zero_disc:
; DYN:       ; %bb.0:
; DYN-NEXT:    adrp x16, _g@GOTPAGE
; DYN-NEXT:    ldr x16, [x16, _g@GOTPAGEOFF]
; DYN-NEXT:    add x16, x16, #16
; DYN-NEXT:    pacdza x16
; DYN-NEXT:    mov x0, x16
; DYN-NEXT:    ret
;
  %tmp0 = bitcast { i8*, i32, i64, i64 }* @g.offset.ptrauth.da.0 to i8*
  ret i8* %tmp0
}

; For large offsets, materializing it can take up to 3 add instructions.
; We limit the offset to 32-bits.  We theoretically could support up to
; 64 bit offsets, but 32 bits Ought To Be Enough For Anybody, and that's
; the limit for the relocation addend anyway.
; But we never use the stub and relocation because of dyld shared cache
; encoding constraints.

define i8* @test_global_big_offset_zero_disc() {
; CHECK-LABEL: test_global_big_offset_zero_disc:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    adrp x16, _g@GOTPAGE
; CHECK-NEXT:    ldr x16, [x16, _g@GOTPAGEOFF]
; CHECK-NEXT:    mov x17, #1 ; =0x1
; CHECK-NEXT:    movk x17, #32769, lsl #16
; CHECK-NEXT:    add x16, x16, x17
; CHECK-NEXT:    pacdza x16
; CHECK-NEXT:    mov x0, x16
; CHECK-NEXT:    ret
  %tmp0 = bitcast { i8*, i32, i64, i64 }* @g.big_offset.ptrauth.da.0 to i8*
  ret i8* %tmp0
}

define i8* @test_global_disc() {
; DYN-LABEL: test_global_disc:
; DYN:       ; %bb.0:
; DYN-NEXT:    adrp x16, _g@GOTPAGE
; DYN-NEXT:    ldr x16, [x16, _g@GOTPAGEOFF]
; DYN-NEXT:    mov x17, #42 ; =0x2a
; DYN-NEXT:    pacia x16, x17
; DYN-NEXT:    mov x0, x16
; DYN-NEXT:    ret
;
  %tmp0 = bitcast { i8*, i32, i64, i64 }* @g.ptrauth.ia.42 to i8*
  ret i8* %tmp0
}

; Process-specific keys can't use __DATA,__auth_ptr

define i8* @test_global_process_specific() {
; DYN-LABEL: test_global_process_specific:
; DYN:       ; %bb.0:
; DYN-NEXT:    adrp x16, _g@GOTPAGE
; DYN-NEXT:    ldr x16, [x16, _g@GOTPAGEOFF]
; DYN-NEXT:    pacizb x16
; DYN-NEXT:    mov x0, x16
; DYN-NEXT:    ret
;
  %tmp0 = bitcast { i8*, i32, i64, i64 }* @g.ptrauth.ib.0 to i8*
  ret i8* %tmp0
}

; weak symbols can't be assumed to be non-nil.  Use __DATA,__auth_ptr always.
; The alternative is to emit a null-check here, but that'd be redundant with
; whatever null-check follows in user code.

define i8* @test_global_weak() {
; CHECK-LABEL: test_global_weak:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    adrp x0, l_g_weak$auth_ptr$ia$42@PAGE
; CHECK-NEXT:    ldr x0, [x0, l_g_weak$auth_ptr$ia$42@PAGEOFF]
; CHECK-NEXT:    ret
  %tmp0 = bitcast { i8*, i32, i64, i64 }* @g_weak.ptrauth.ia.42 to i8*
  ret i8* %tmp0
}

define i8* @test_global_addr_disc() {
; DYN-CM-DFL-LABEL: test_global_addr_disc:
; DYN-CM-DFL:       ; %bb.0:
; DYN-CM-DFL-NEXT:  Lloh{{.*}}:
; DYN-CM-DFL-NEXT:    adrp x8, _g.ref.da.42.addr@PAGE
; DYN-CM-DFL-NEXT:  Lloh{{.*}}:
; DYN-CM-DFL-NEXT:    add x8, x8, _g.ref.da.42.addr@PAGEOFF
; DYN-CM-DFL-NEXT:    adrp x16, _g@GOTPAGE
; DYN-CM-DFL-NEXT:    ldr x16, [x16, _g@GOTPAGEOFF]
; DYN-CM-DFL-NEXT:    mov x17, x8
; DYN-CM-DFL-NEXT:    movk x17, #42, lsl #48
; DYN-CM-DFL-NEXT:    pacda x16, x17
; DYN-CM-DFL-NEXT:    mov x0, x16
; DYN-CM-DFL-NEXT:    ret
;
;
; DYN-CM-LRG-LABEL: test_global_addr_disc:
; DYN-CM-LRG:       ; %bb.0:
; DYN-CM-LRG-NEXT:  Lloh{{.*}}:
; DYN-CM-LRG-NEXT:    adrp x8, _g.ref.da.42.addr@GOTPAGE
; DYN-CM-LRG-NEXT:  Lloh{{.*}}:
; DYN-CM-LRG-NEXT:    ldr x8, [x8, _g.ref.da.42.addr@GOTPAGEOFF]
; DYN-CM-LRG-NEXT:    adrp x16, _g@GOTPAGE
; DYN-CM-LRG-NEXT:    ldr x16, [x16, _g@GOTPAGEOFF]
; DYN-CM-LRG-NEXT:    mov x17, x8
; DYN-CM-LRG-NEXT:    movk x17, #42, lsl #48
; DYN-CM-LRG-NEXT:    pacda x16, x17
; DYN-CM-LRG-NEXT:    mov x0, x16
; DYN-CM-LRG-NEXT:    ret
  %tmp0 = bitcast { i8*, i32, i64, i64 }* @g.ptrauth.da.42.addr to i8*
  ret i8* %tmp0
}

; Non-external symbols don't need to be accessed through the GOT: always prefer
; the dynamic materialization sequence, with adrp+add rather than a GOT load.

define i8* @test_global_strong_def() {
; DYN-CM-DFL-LABEL: test_global_strong_def:
; DYN-CM-DFL:       ; %bb.0:
; DYN-CM-DFL-NEXT:    adrp x16, _g_strong_def@PAGE
; DYN-CM-DFL-NEXT:    add x16, x16, _g_strong_def@PAGEOFF
; DYN-CM-DFL-NEXT:    pacdza x16
; DYN-CM-DFL-NEXT:    mov x0, x16
; DYN-CM-DFL-NEXT:    ret
;
; DYN-CM-LRG-LABEL: test_global_strong_def:
; DYN-CM-LRG:       ; %bb.0:
; DYN-CM-LRG-NEXT:    adrp x16, _g_strong_def@GOTPAGE
; DYN-CM-LRG-NEXT:    ldr x16, [x16, _g_strong_def@GOTPAGEOFF]
; DYN-CM-LRG-NEXT:    pacdza x16
; DYN-CM-LRG-NEXT:    mov x0, x16
; DYN-CM-LRG-NEXT:    ret
  %tmp0 = bitcast { i8*, i32, i64, i64 }* @g_strong_def.ptrauth.da.0 to i8*
  ret i8* %tmp0
}

; Check global references.

@g = external global i32

@g_weak = extern_weak global i32

@g_strong_def = constant i32 42

; CHECK-LABEL:   .section __DATA,__const
; CHECK-NEXT:    .globl _g.ref.ia.0
; CHECK-NEXT:    .p2align 4
; CHECK-NEXT:  _g.ref.ia.0:
; CHECK-NEXT:    .quad 5
; CHECK-NEXT:    .quad _g@AUTH(ia,0)
; CHECK-NEXT:    .quad 6

@g.ptrauth.ia.0 = private constant { i8*, i32, i64, i64 } { i8* bitcast (i32* @g to i8*), i32 0, i64 0, i64 0 }, section "llvm.ptrauth"

@g.ref.ia.0 = constant { i64, i8*, i64 } { i64 5, i8* bitcast ({ i8*, i32, i64, i64 }* @g.ptrauth.ia.0 to i8*), i64 6 }

; CHECK-LABEL:   .globl _g.ref.ia.42
; CHECK-NEXT:    .p2align 3
; CHECK-NEXT:  _g.ref.ia.42:
; CHECK-NEXT:    .quad _g@AUTH(ia,42)

@g.ptrauth.ia.42 = private constant { i8*, i32, i64, i64 } { i8* bitcast (i32* @g to i8*), i32 0, i64 0, i64 42 }, section "llvm.ptrauth"

@g.ref.ia.42 = constant i8* bitcast ({ i8*, i32, i64, i64 }* @g.ptrauth.ia.42 to i8*)

; CHECK-LABEL:   .globl _g.ref.ib.0
; CHECK-NEXT:    .p2align 4
; CHECK-NEXT:  _g.ref.ib.0:
; CHECK-NEXT:    .quad 5
; CHECK-NEXT:    .quad _g@AUTH(ib,0)
; CHECK-NEXT:    .quad 6

@g.ptrauth.ib.0 = private constant { i8*, i32, i64, i64 } { i8* bitcast (i32* @g to i8*), i32 1, i64 0, i64 0 }, section "llvm.ptrauth"

@g.ref.ib.0 = constant { i64, i8*, i64 } { i64 5, i8* bitcast ({ i8*, i32, i64, i64 }* @g.ptrauth.ib.0 to i8*), i64 6 }


; CHECK-LABEL:   .globl _g.ref.da.42.addr
; CHECK-NEXT:    .p2align 3
; CHECK-NEXT:  _g.ref.da.42.addr:
; CHECK-NEXT:    .quad _g@AUTH(da,42,addr)

@g.ptrauth.da.42.addr = private constant { i8*, i32, i64, i64 } { i8* bitcast (i32* @g to i8*), i32 2, i64 ptrtoint (i8** @g.ref.da.42.addr to i64), i64 42 }, section "llvm.ptrauth"

@g.ref.da.42.addr = constant i8* bitcast ({ i8*, i32, i64, i64 }* @g.ptrauth.da.42.addr to i8*)

; CHECK-LABEL:   .globl _g.offset.ref.da.0
; CHECK-NEXT:    .p2align 3
; CHECK-NEXT:  _g.offset.ref.da.0:
; CHECK-NEXT:    .quad (_g+16)@AUTH(da,0)

@g.offset.ptrauth.da.0 = private constant { i8*, i32, i64, i64 } { i8* getelementptr (i8, i8* bitcast (i32* @g to i8*), i64 16), i32 2, i64 0, i64 0 }, section "llvm.ptrauth"

@g.offset.ref.da.0 = constant i8* bitcast ({ i8*, i32, i64, i64 }* @g.offset.ptrauth.da.0 to i8*)

; CHECK-LABEL:   .globl _g.big_offset.ref.da.0
; CHECK-NEXT:    .p2align 3
; CHECK-NEXT:  _g.big_offset.ref.da.0:
; CHECK-NEXT:    .quad (_g+2147549185)@AUTH(da,0)

@g.big_offset.ptrauth.da.0 = private constant { i8*, i32, i64, i64 } { i8* getelementptr (i8, i8* bitcast (i32* @g to i8*), i64 add (i64 2147483648, i64 65537)), i32 2, i64 0, i64 0 }, section "llvm.ptrauth"

@g.big_offset.ref.da.0 = constant i8* bitcast ({ i8*, i32, i64, i64 }* @g.big_offset.ptrauth.da.0 to i8*)

; CHECK-LABEL:   .globl _g.weird_ref.da.0
; CHECK-NEXT:    .p2align 3
; CHECK-NEXT:  _g.weird_ref.da.0:
; CHECK-NEXT:    .quad (_g+16)@AUTH(da,0)

@g.weird_ref.da.0 = constant i64 ptrtoint (i8* bitcast (i64* inttoptr (i64 ptrtoint (i8* bitcast ({ i8*, i32, i64, i64 }* @g.offset.ptrauth.da.0 to i8*) to i64) to i64*) to i8*) to i64)

; CHECK-LABEL:   .globl _g_weak.ref.ia.42
; CHECK-NEXT:    .p2align 3
; CHECK-NEXT:  _g_weak.ref.ia.42:
; CHECK-NEXT:    .quad _g_weak@AUTH(ia,42)

@g_weak.ptrauth.ia.42 = private constant { i8*, i32, i64, i64 } { i8* bitcast (i32* @g_weak to i8*), i32 0, i64 0, i64 42 }, section "llvm.ptrauth"

@g_weak.ref.ia.42 = constant i8* bitcast ({ i8*, i32, i64, i64 }* @g_weak.ptrauth.ia.42 to i8*)

; CHECK-LABEL:   .globl _g_strong_def.ref.da.0
; CHECK-NEXT:    .p2align 3
; CHECK-NEXT:  _g_strong_def.ref.da.0:
; CHECK-NEXT:    .quad _g_strong_def@AUTH(da,0)

@g_strong_def.ptrauth.da.0 = private constant { i8*, i32, i64, i64 } { i8* bitcast (i32* @g_strong_def to i8*), i32 2, i64 0, i64 0 }, section "llvm.ptrauth"

@g_strong_def.ref.da.0 = constant i8* bitcast ({ i8*, i32, i64, i64 }* @g_strong_def.ptrauth.da.0 to i8*)
